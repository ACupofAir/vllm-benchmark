diff --git a/csrc/ktransformers_ext/operators/llamafile/moe.cpp b/csrc/ktransformers_ext/operators/llamafile/moe.cpp
index cd42691..6328a60 100644
--- a/csrc/ktransformers_ext/operators/llamafile/moe.cpp
+++ b/csrc/ktransformers_ext/operators/llamafile/moe.cpp
@@ -15,12 +15,24 @@
 #include <numa.h>
 #include <numaif.h>
 #endif
+#include <sys/mman.h>
+#include <unistd.h>
 
 MOE::MOE(MOEConfig config) {
     config_ = config;
     gate_proj_ = config_.gate_proj;
     up_proj_ = config_.up_proj;
     down_proj_ = config_.down_proj;
+
+    
+    expert_size = config_.intermediate_size * 
+    config_.hidden_size *
+    ggml_type_size(config_.gate_type) / 
+    ggml_blck_size(config_.gate_type);
+    page_size = sysconf(_SC_PAGESIZE); // 获取系统页大小[3](@ref)
+    std::cout<<"******moeinit***************************";
+
+
     
     #ifdef USE_NUMA
     int numa_nodes = numa_num_configured_nodes();
@@ -105,6 +117,8 @@ MOE::MOE(MOEConfig config) {
 MOE::~MOE() {
     shared_mem_buffer.dealloc(this);
 
+    
+
     #ifdef USE_NUMA
     int numa_nodes = numa_num_configured_nodes();
     for (int i = 0; i < numa_nodes; i++) {
@@ -126,7 +140,7 @@ void MOE::warm_up(Backend* backend) {
     for (int i = 0; i < config_.expert_num; i++) {
         uint64_t expert_ids = i;
         float weights = 0;
-        forward_one(1, &expert_ids, &weights, input.data(), output.data(), backend);
+        forward_one(1, &expert_ids, &weights, input.data(), output.data(), backend,true);
     }
 }
 
@@ -134,7 +148,155 @@ static float act_fn(float x) {
     return x / (1.0f + expf(-x));
 }
 
-void MOE::forward_one(int k, const uint64_t* expert_ids, const float* weights, const void* input, void* output, Backend* backend) {
+
+
+void MOE::forward_one(int k, const uint64_t* expert_ids, const float* weights, const void* input, void* output, Backend* backend,bool iswarm) {
+    //printf("==%d=================%d===========",expert_size,page_size);
+        /*moonll
+        内存充足时无需开启，会降低性能
+        */
+    if (0){
+        for (int i=0; i<k; ++i) {
+            uint64_t expert_id = expert_ids[i];
+        
+            if (!locked_experts.count(expert_id)) {
+            //    std::cout<<"******write**********"<<expert_id<<"*******************========"<<order.size();
+                #ifdef USE_NUMA
+                void* base_ptr = gate_proj_numa_[Backend::numa_node];
+                #else
+                void* base_ptr = gate_proj_;
+                #endif
+                
+                // 计算参数块地址边界
+                void* start_ptr = (uint8_t*)base_ptr + expert_id * expert_size;
+                void* end_ptr = (uint8_t*)start_ptr + expert_size;
+                
+                // 按页对齐处理[3](@ref)
+                uintptr_t aligned_start_b = (uintptr_t)start_ptr & ~(page_size-1);
+                uintptr_t aligned_end_b = ((uintptr_t)end_ptr + page_size-1) & ~(page_size-1);
+                size_t aligned_length_b = aligned_end_b - aligned_start_b;
+
+                base_ptr = up_proj_;
+                // 计算参数块地址边界
+                start_ptr = (uint8_t*)base_ptr + expert_id * expert_size;
+                end_ptr = (uint8_t*)start_ptr + expert_size;
+                
+                // 按页对齐处理[3](@ref)
+                uintptr_t aligned_start_u = (uintptr_t)start_ptr & ~(page_size-1);
+                uintptr_t aligned_end_u = ((uintptr_t)end_ptr + page_size-1) & ~(page_size-1);
+                size_t aligned_length_u = aligned_end_u - aligned_start_u;
+
+
+                base_ptr = down_proj_;
+                // 计算参数块地址边界
+                start_ptr = (uint8_t*)base_ptr + expert_id * expert_size;
+                end_ptr = (uint8_t*)start_ptr + expert_size;
+                
+                // 按页对齐处理[3](@ref)
+                uintptr_t aligned_start_d = (uintptr_t)start_ptr & ~(page_size-1);
+                uintptr_t aligned_end_d = ((uintptr_t)end_ptr + page_size-1) & ~(page_size-1);
+                size_t aligned_length_d = aligned_end_d - aligned_start_d;
+
+                
+
+
+
+
+               // if(0)
+                if(order.size()>120)
+                {
+                    
+                    uint64_t dexpert_id=order.front();
+                    base_ptr = gate_proj_;
+                     // 计算参数块地址边界
+                    start_ptr = (uint8_t*)base_ptr + dexpert_id * expert_size;
+                    end_ptr = (uint8_t*)start_ptr + expert_size;
+                    
+                    // 按页对齐处理[3](@ref)
+                    uintptr_t daligned_start_b = (uintptr_t)start_ptr & ~(page_size-1);
+                    uintptr_t daligned_end_b = ((uintptr_t)end_ptr + page_size-1) & ~(page_size-1);
+                    size_t daligned_length_b = daligned_end_b - daligned_start_b;
+
+                    base_ptr = up_proj_;
+                    // 计算参数块地址边界
+                    start_ptr = (uint8_t*)base_ptr + dexpert_id * expert_size;
+                    end_ptr = (uint8_t*)start_ptr + expert_size;
+                    
+                    // 按页对齐处理[3](@ref)
+                    uintptr_t daligned_start_u = (uintptr_t)start_ptr & ~(page_size-1);
+                    uintptr_t daligned_end_u = ((uintptr_t)end_ptr + page_size-1) & ~(page_size-1);
+                    size_t daligned_length_u = daligned_end_u - daligned_start_u;
+
+
+                    base_ptr = down_proj_;
+                    // 计算参数块地址边界
+                    start_ptr = (uint8_t*)base_ptr + dexpert_id * expert_size;
+                    end_ptr = (uint8_t*)start_ptr + expert_size;
+                    
+                    // 按页对齐处理[3](@ref)
+                    uintptr_t daligned_start_d = (uintptr_t)start_ptr & ~(page_size-1);
+                    uintptr_t daligned_end_d = ((uintptr_t)end_ptr + page_size-1) & ~(page_size-1);
+                    size_t daligned_length_d = daligned_end_d - daligned_start_d;
+
+                    munlock((void*)daligned_start_b,daligned_length_b);
+                    munlock((void*)daligned_start_u,daligned_length_u);
+                    munlock((void*)daligned_start_d,daligned_length_d);
+                    /*
+                    munmap((void*)daligned_start_b,daligned_length_b);
+                    munmap((void*)daligned_start_u,daligned_length_u);
+                    munmap((void*)daligned_start_d,daligned_length_d);*/
+
+                    locked_experts.erase(order.front());
+                    order.pop_front();
+                 //   std::cout<<"******delete**********"<<dexpert_id<<"*******************========"<<order.size();
+
+
+                }
+    
+                if (mlock((void*)aligned_start_b, aligned_length_b) == 0) {
+                    locked_experts.insert(expert_id);
+                    order.push_back(expert_id);
+                 //   std::cout<<"-"<<expert_id<<"-";
+                } else {
+                    //std::cout<<"******failed**********"<<expert_id<<"*********************************";
+                    perror("mlock failed"); // 处理权限不足或内存限制
+                }
+    
+                //=====================================================
+    
+              
+    
+                if (mlock((void*)aligned_start_u, aligned_length_u) == 0) {
+                   // locked_experts.insert(expert_id);
+                  //  std::cout<<"*********************"<<expert_id<<"*********************************";
+                } else {
+                  //  std::cout<<"******failed**********"<<expert_id<<"*********************************";
+                    perror("mlock failed"); // 处理权限不足或内存限制
+                }
+    
+    
+                if (mlock((void*)aligned_start_d, aligned_length_d) == 0) {
+                  //  locked_experts.insert(expert_id);
+                    //std::cout<<"*********************"<<expert_id<<"*********************************";
+                } else {
+                    //std::cout<<"******failed**********"<<expert_id<<"*********************************";
+                    perror("mlock failed"); // 处理权限不足或内存限制
+                }
+            }
+           
+            else
+            {
+              //  std::cout<<"******hit**********"<<expert_id<<"*********************************";
+            }
+           
+        }
+    }
+    else
+    {
+      //  return;
+    }
+
+
     const void* gate_input_ptr;
     const void* up_input_ptr;
     if (config_.hidden_type == ggml_internal_get_type_traits(config_.gate_type).vec_dot_type && config_.hidden_type == ggml_internal_get_type_traits(config_.up_type).vec_dot_type) {
@@ -345,13 +507,12 @@ void MOE::forward(int qlen, int k, const uint64_t* expert_ids, const float* weig
     qlen = batch_size_tensor[0];
     if (qlen < config_.group_min_len) {
         for (int i = 0; i < qlen; i++) {
-            forward_one(k, expert_ids + i * k, weights + i * k, (uint8_t*)input + i * config_.hidden_size * ggml_type_size(config_.hidden_type) / ggml_blck_size(config_.hidden_type), (uint8_t*)output + i * config_.hidden_size * ggml_type_size(config_.hidden_type) / ggml_blck_size(config_.hidden_type), backend);
+            forward_one(k, expert_ids + i * k, weights + i * k, (uint8_t*)input + i * config_.hidden_size * ggml_type_size(config_.hidden_type) / ggml_blck_size(config_.hidden_type), (uint8_t*)output + i * config_.hidden_size * ggml_type_size(config_.hidden_type) / ggml_blck_size(config_.hidden_type), backend,false);
         }
         return;
     }
     int forward_len = std::min(config_.group_max_len, qlen);
     forward_many(forward_len, k, expert_ids, weights, input, output, backend);
-
     batch_size_tensor[0] -= forward_len;
     forward(qlen - forward_len, k, expert_ids + forward_len * k, weights + forward_len * k, (uint8_t*)input + forward_len * config_.hidden_size * ggml_type_size(config_.hidden_type) / ggml_blck_size(config_.hidden_type), (uint8_t*)output + forward_len * config_.hidden_size * ggml_type_size(config_.hidden_type) / ggml_blck_size(config_.hidden_type), batch_size_tensor, backend);
 }
\ No newline at end of file
diff --git a/csrc/ktransformers_ext/operators/llamafile/moe.h b/csrc/ktransformers_ext/operators/llamafile/moe.h
index 28d7ad3..deaf989 100644
--- a/csrc/ktransformers_ext/operators/llamafile/moe.h
+++ b/csrc/ktransformers_ext/operators/llamafile/moe.h
@@ -17,12 +17,16 @@
 #include <vector>
 
 #include "../../cpu_backend/backend.h"
-#include "../../cpu_backend/shared_mem_buffer.h"
 #include "conversion.h"
 #include "llama.cpp/ggml-impl.h"
 #include "llama.cpp/ggml-quants.h"
 #include "llama.cpp/ggml.h"
 #include "llamafile/sgemm.h"
+#include "../../cpu_backend/shared_mem_buffer.h"
+#include <unordered_set>
+#include <deque>
+
+
 
 struct MOEConfig {
     int expert_num;
@@ -51,15 +55,19 @@ class MOE {
     MOE(MOEConfig);
     ~MOE();
     void warm_up(Backend* backend);
-    void forward_one(int k, const uint64_t* expert_ids, const float* weights, const void* input, void* output, Backend* backend);
+    void forward_one(int k, const uint64_t* expert_ids, const float* weights, const void* input, void* output, Backend* backend,bool iswarm);
     void forward_many(int qlen, int k, const uint64_t* expert_ids, const float* weights, const void* input, void* output, Backend* backend);
-    void forward(int qlen, int k, const uint64_t* expert_ids, const float* weights, const void* input, void* output, int* batch_size_tensor, Backend* backend);
+    void forward(int qlen, int k, const uint64_t* expert_ids, const float* weights, const void* input, void* output,int* batch_size_tensor,Backend* backend);
 
    private:
     MOEConfig config_;
     void* gate_proj_;  // [expert_num * intermediate_size * hidden_size ( /32 if quantized)]
     void* up_proj_;    // [expert_num * intermediate_size * hidden_size ( /32 if quantized)]
     void* down_proj_;  // [expert_num * hidden_size * intermediate_size ( /32 if quantized)]
+    std::deque<uint64_t> order;
+    std::unordered_set<uint64_t> locked_experts;
+    size_t expert_size;
+    size_t page_size;
 
     #ifdef USE_NUMA
     std::vector<void*> gate_proj_numa_;  // [numa_num, expert_num * intermediate_size * hidden_size ( /32 if quantized)]
diff --git a/third_party/llamafile/iqk_mul_mat.inc b/third_party/llamafile/iqk_mul_mat.inc
old mode 100644
new mode 100755
index a4e8c41..471c9b2
--- a/third_party/llamafile/iqk_mul_mat.inc
+++ b/third_party/llamafile/iqk_mul_mat.inc
@@ -1,9 +1,6 @@
 // Adapted from
 // https://github.com/Mozilla-Ocho/llamafile/blob/0.8.8/llamafile/iqk_mul_mat.inc
-// Copyrigth 2024 Iwan Kawrakow - Apache 2.0 Licens
-// with additions from
-// https://github.com/ikawrakow/ik_llama.cpp/blob/main/ggml/src/iqk/iqk_mul_mat.cpp
-// Copyrigth 2024-2025 Iwan Kawrakow - MIT Licens
+// Copyrigth 2024 Iwan Kawrakow.
 // Copyright(c) 2024 by KVCache.AI, All Rights Reserved.
 
 // -*- mode:c++;indent-tabs-mode:nil;c-basic-offset:4;coding:utf-8 -*-
@@ -22,12 +19,6 @@
 // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 // See the License for the specific language governing permissions and
 // limitations under the License.
-//
-//
-// Copyright (C) 2024-2025 Iwan Kawrakow
-// MIT license
-// SPDX-License-Identifier: MIT
-//
 
 #include <cstring>
 #include <type_traits>
@@ -134,8 +125,6 @@ struct MulMat {
     IQK_NOINLINE void mul_mat_NxM(int n, const void * vx, size_t bx, DataInfo& info, int nrc_x, int nrc_y) {
         constexpr int k_x_step = 64; // This works best on my Ryzen-7950X and M2 Max CPUs (but differences to other tile size are small)
 
-        // copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L162
-        // MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
         if (func16 && nrc_y >= 16) {
             int n_step = (nrc_y - info.cur_y)/16;
             for (int ix = 0; ix < nrc_x; ix += k_x_step) {
@@ -150,7 +139,6 @@ struct MulMat {
             info.cur_y += 16 * n_step;
             if (info.cur_y == nrc_y) return;
         }
-        // end copy
 
         int n_step = (nrc_y - info.cur_y)/funcs.size();
         if (n_step > 0) {
@@ -190,8 +178,6 @@ inline void make_q4_scales(const uint8_t * scales8, uint32_t * aux32) {
 moonll
 decoding tables
 */
-// copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L570
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 #ifdef __AVX2__
 static const uint64_t iq1s_grid_us[2048] = {
     0x0000000000000000, 0x0000000000000002, 0x0000000000000101, 0x0000000000000200,
@@ -967,7 +953,6 @@ static const uint32_t iq1s_grid_us[2048] = {
     0x22202022, 0x22202220, 0x22202222, 0x22212121, 0x22222020, 0x22222022, 0x22222220, 0x22222222,
 };
 #endif
-// end copy https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L570
 
 #ifndef HAVE_FANCY_SIMD
 const uint64_t keven_signs[128] = {
@@ -1012,8 +997,6 @@ const uint64_t keven_signs[128] = {
 add typeB and strideB
 }*/
 
-// Adapted from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L406
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 bool iqk_mul_mat(long Nx, long Ny, long ne00,
     int typeA, const void * A, long strideA,
     int typeB, const void * B, long strideB,
@@ -1039,7 +1022,6 @@ bool iqk_mul_mat(long Nx, long Ny, long ne00,
 
         return true;
 }
-// end adapted from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L406
 
 
 bool iqk_mul_mat_moe(long Nx, long Ny, long ne00, int ne11, int typeA, const void * A, const void * B,
@@ -1191,8 +1173,6 @@ struct ScaleIQ4XS {
     const __m128i m32 = _mm_set1_epi16(-32);
 };
 
-// Copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L1455
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 struct Scales8KBase {
     template <typename Q8>
     inline void accum_mins(const __m128i& mins128, const Q8& q8, int i, float c, __m256 * accd) const {
@@ -1209,7 +1189,6 @@ struct Scales8KBase {
     const __m128i shuffles[2] = {_mm_set_epi32(0x07060706, 0x05040504, 0x03020302, 0x01000100),
                                  _mm_set_epi32(0x0f0e0f0e, 0x0d0c0d0c, 0x0b0a0b0a, 0x09080908)};
 };
-// end copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L1455
 
 template <typename Block>
 struct BaseDequantizer {
@@ -1225,8 +1204,6 @@ struct BaseDequantizer {
     float d;
 };
 
-// Copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L1698
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 __m128i inline load_iq4nl_values_128() {
     static const uint8_t kvalues_iq4nl[16] = {1, 24, 45, 63, 79, 93, 106, 118, 129, 141, 153, 166, 181, 197, 217, 241};
     return _mm_loadu_si128((const __m128i *)kvalues_iq4nl);
@@ -1236,7 +1213,6 @@ __m256i inline load_iq4nl_values_256() {
     auto val128 = load_iq4nl_values_128();
     return MM256_SET_M128I(val128, val128);
 }
-// end copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L1698
 
 #ifdef HAVE_FANCY_SIMD
 //====================================== Zen4 ==================================================
@@ -1309,18 +1285,12 @@ struct DequantizerQ4K final : public BaseDequantizer<block_q4_K> {
 moonll DequantizerIQ4XS
 */
 
-// Copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L1775
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 __m512i inline load_iq4nl_values_512() {
     auto val256 = load_iq4nl_values_256();
     return _mm512_inserti32x8(_mm512_castsi256_si512(val256), val256, 1);
 }
-// end copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L1775
 
-// Copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L1781
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 struct DequantizerIQ4XS final : public BaseDequantizer<block_iq4_xs> {
-    // Copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L1782
     DequantizerIQ4XS(const void * vx, size_t bx) : BaseDequantizer(vx, bx), values(load_iq4nl_values_512()) {}
     template <typename Q8>
     inline void new_block(int i, const Q8& q8, __m256 * accd, __m512i * scales) {
@@ -1361,7 +1331,6 @@ struct DequantizerIQ4XS final : public BaseDequantizer<block_iq4_xs> {
         _mm512_inserti32x8(_mm512_set1_epi16(0x0d0c), _mm256_set1_epi16(0x0f0e), 1),
     };
 };
-// end copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L1781
 
 struct HighBit5 {
     inline void apply(const uint8_t * h, Q4Bits& bits) {
@@ -1535,8 +1504,6 @@ static void mul_mat_qX_K_q8_K_T(int n, const void * vx, size_t bx, const DataInf
 
     }
 }
-// Copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L2408
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 template <typename Q8>
 inline void compute_block(int iy, int i, float d, const Q8& q8, const __m512i * values, const __m512i * scales, __m512 * accd) {
     const __m512i p1 = _mm512_dpbusd_epi32(_mm512_setzero_si512(), values[0], q8.load_quants64(iy, i, 0));
@@ -1680,7 +1647,6 @@ static void mul_mat_qX_K_q8_K_AVX512_1(int n, const void * vx, size_t bx, const
         info.store(ix, 0, hsum_float_8(_mm256_add_ps(accm, sum256)));
     }
 }
-// end copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L2408
 
 #else
 // ===================================== Vanilla AVX2 =====================================
@@ -1915,7 +1881,6 @@ struct DequantizerQ6K final : public BaseDequantizer<block_q6_K> {
     const __m256i mh = _mm256_set1_epi8(0x30);
 };
 
-
 inline __m256i get_scale_shuffle_8(int i);
 
 inline void set_scales_8(const __m256i& all_scales, int j, __m256i* scales);
@@ -2096,8 +2061,6 @@ struct ScaleHelperQ_0 {
     template <typename Q> inline float prepare1(const Q * y) const { return GGML_FP16_TO_FP32(y->d); }
     template <typename Q> inline float prepare1(float d, const Q * y) const { return d*prepare1(y); }
 };
-// Copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L8187
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 template <int min_value>
 struct ScaleHelperQ_0_1 {
     ggml_half scales8[4];
@@ -2120,7 +2083,6 @@ struct ScaleHelperQ_0_1 {
     }
     const __m128 min = _mm_set1_ps(float(-min_value));
 };
-// end copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L8187
 
 struct ScaleHelperQ_1 {
     uint32_t scales8[4];
@@ -2281,14 +2243,11 @@ struct Q8_0_Dequantizer {
     }
 };
 
-// Copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L8455
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 struct Q8_0_1_Dequantizer {
     inline __m256i dequant(const block_q8_0 * x) const {
         return _mm256_add_epi8(_mm256_set1_epi8(127), _mm256_loadu_si256((const __m256i *)x->qs));
     }
 };
-// end copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L8455
 
 struct Q4_0_Dequantizer {
     Dequantizer4bit b4;
@@ -2375,14 +2334,11 @@ struct Q8_0_Unpacker final : public Q_Unpacker<block_q8_0, ScaleHelperQ_0, Q8_0_
     Q8_0_Unpacker(const void * vx, size_t bx) : Q_Unpacker(vx, bx) {}
     inline static int block_size() { return QK4_0; }
 };
-// Copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L8574
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 struct Q8_0_1_Unpacker final : public Q_Unpacker<block_q8_0, ScaleHelperQ_0_1<127>, Q8_0_1_Dequantizer> {
     Q8_0_1_Unpacker(const void * vx, size_t bx) : Q_Unpacker(vx, bx) {}
 //    using Sum4T = Sum4TypeQ81;
     inline static int block_size() { return QK8_0; }
 };
-// end copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L8574
 struct Q4_0_Unpacker final : public Q_Unpacker<block_q4_0, ScaleHelperQ_0, Q4_0_Dequantizer> {
     Q4_0_Unpacker(const void * vx, size_t bx) : Q_Unpacker(vx, bx) {}
     inline static int block_size() { return QK4_0; }
@@ -2429,16 +2385,13 @@ struct SimpleBits {
     __m256i values[4];
 };
 
-// fix for #829: Add checks of AVX512VPOPCNTDQ
+// fix for #829: 添加对 AVX512VPOPCNTDQ 的检测
 #if defined(HAVE_FANCY_SIMD) && defined(__AVX512VPOPCNTDQ__)
 #define HAVE_AVX512_POPCNT 1
 #else
 #define HAVE_AVX512_POPCNT 0
 #endif
 
-// Copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L7736
-// with the addition of a branch that handles a missing _mm256_popcnt_epi32 instruction
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 struct EvenSignHelper {
     #if defined HAVE_FANCY_SIMD
     // #pragma message("Using AVX512VPOPCNTDQ in even sign helper")
@@ -2449,20 +2402,19 @@ struct EvenSignHelper {
         IQK_ALWAYS_INLINE void sign_2_values(__m256i aux, __m256i * values) const {
             aux = _mm256_and_si256(_mm256_srlv_epi32(aux, shifts), mask);
             
-            // fix for #829: Compatibility with processors using Intel Cascade Lake architecture
-            // If AVX512VPOPCNTDQ extension is not supported, use alternative implementation
+            // fix for #829: 兼容Intel Cascade Lake架构的CPU，如果不支持AVX512VPOPCNTDQ扩展，则使用替代实现
             #if HAVE_AVX512_POPCNT
                 auto pcnt = _mm256_popcnt_epi32(aux);
                 
             #else
-                // Alternative implementation: Using standard bit counting method
+                // 提供替代实现，使用标准的位计数方法
                 __m256i pcnt;
                 int* pcnt_ptr = reinterpret_cast<int*>(&pcnt);
-                int* aux_ptr = reinterpret_cast<int*>(&aux); // Get address of aux directly, avoid unnecessary copies
+                int* aux_ptr = reinterpret_cast<int*>(&aux); // 直接获取 aux 的地址，避免不必要的复制
                 
-                #pragma unroll 8  // Hint compiler to unroll loops, increasing throughput of SIMD computing
+                #pragma unroll 8  // 提示编译器展开循环，提高 SIMD 计算吞吐量
                 for (int i = 0; i < 8; i++) {
-                    pcnt_ptr[i] = __builtin_popcount(aux_ptr[i]); // Use compiler builtin popcount
+                    pcnt_ptr[i] = __builtin_popcount(aux_ptr[i]); // 使用编译器内置 popcount
                 }
             #endif
             
@@ -2495,8 +2447,6 @@ get_scale_shuffle_16
 set_scales_16
 */
 
-// Copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L1578
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 inline __m256i get_scale_shuffle_8(int i) {
     return _mm256_set1_epi16((2*i) | ((2*i+1) << 8));
 }
@@ -2526,6 +2476,7 @@ inline void set_scales_16(const __m256i& all_scales, __m256i * scales) {
     scales[3] = _mm256_shuffle_epi8(all_scales, get_scale_shuffle_16(3));
 }
 
+
 template <typename Q8, typename Bits>
 inline void multiply_add(const Bits& bits, const __m256i * scales, int j, int i, const Q8& q8, __m256i * sumi) {
     if (j == 0) {
@@ -2536,6 +2487,13 @@ inline void multiply_add(const Bits& bits, const __m256i * scales, int j, int i,
             sumi[iy] = _mm256_dpwssd_epi32(sumi[iy], scales[2], _mm256_maddubs_epi16(bits.values[2], q8.load_quants(iy, i, 2)));
             sumi[iy] = _mm256_dpwssd_epi32(sumi[iy], scales[3], _mm256_maddubs_epi16(bits.values[3], q8.load_quants(iy, i, 3)));
         }
+#elif __AVXVNNI__
+        for (int iy = 0; iy < Q8::nrc_y; ++iy) {
+            sumi[iy] = _mm256_dpwssd_epi32(_mm256_setzero_si256(), scales[0], _mm256_maddubs_epi16(bits.values[0], q8.load_quants(iy, i, 0)));
+            sumi[iy] = _mm256_dpwssd_epi32(sumi[iy], scales[1], _mm256_maddubs_epi16(bits.values[1], q8.load_quants(iy, i, 1)));
+            sumi[iy] = _mm256_dpwssd_epi32(sumi[iy], scales[2], _mm256_maddubs_epi16(bits.values[2], q8.load_quants(iy, i, 2)));
+            sumi[iy] = _mm256_dpwssd_epi32(sumi[iy], scales[3], _mm256_maddubs_epi16(bits.values[3], q8.load_quants(iy, i, 3)));
+        }
 #else
         for (int iy = 0; iy < Q8::nrc_y; ++iy) {
             const __m256i p1 = _mm256_madd_epi16(scales[0], _mm256_maddubs_epi16(bits.values[0], q8.load_quants(iy, i, 0)));
@@ -2553,6 +2511,13 @@ inline void multiply_add(const Bits& bits, const __m256i * scales, int j, int i,
             sumi[iy] = _mm256_dpwssd_epi32(sumi[iy], scales[2], _mm256_maddubs_epi16(bits.values[2], q8.load_quants(iy, i, 6)));
             sumi[iy] = _mm256_dpwssd_epi32(sumi[iy], scales[3], _mm256_maddubs_epi16(bits.values[3], q8.load_quants(iy, i, 7)));
         }
+#elif __AVXVNNI__
+        for (int iy = 0; iy < Q8::nrc_y; ++iy) {
+            sumi[iy] = _mm256_dpwssd_epi32(sumi[iy], scales[0], _mm256_maddubs_epi16(bits.values[0], q8.load_quants(iy, i, 4)));
+            sumi[iy] = _mm256_dpwssd_epi32(sumi[iy], scales[1], _mm256_maddubs_epi16(bits.values[1], q8.load_quants(iy, i, 5)));
+            sumi[iy] = _mm256_dpwssd_epi32(sumi[iy], scales[2], _mm256_maddubs_epi16(bits.values[2], q8.load_quants(iy, i, 6)));
+            sumi[iy] = _mm256_dpwssd_epi32(sumi[iy], scales[3], _mm256_maddubs_epi16(bits.values[3], q8.load_quants(iy, i, 7)));
+        }
 #else
         for (int iy = 0; iy < Q8::nrc_y; ++iy) {
             const __m256i p1 = _mm256_madd_epi16(scales[0], _mm256_maddubs_epi16(bits.values[0], q8.load_quants(iy, i, 4)));
@@ -2588,6 +2553,13 @@ inline void multiply_add_1(int j, const Bits& bits, const __m256i * scales, cons
         auto p4 = _mm256_dpbusd_epi32(_mm256_setzero_si256(), bits.values[3], q8[3]);
         sumi[0] = _mm256_dpwssd_epi32(_mm256_setzero_si256(), scales[0], _mm256_packs_epi32(p1, p2));
         sumi[1] = _mm256_dpwssd_epi32(_mm256_setzero_si256(), scales[1], _mm256_packs_epi32(p3, p4));
+#elif __AVXVNNI__
+        auto p1 = _mm256_dpbusd_epi32(_mm256_setzero_si256(), bits.values[0], q8[0]);
+        auto p2 = _mm256_dpbusd_epi32(_mm256_setzero_si256(), bits.values[1], q8[1]);
+        auto p3 = _mm256_dpbusd_epi32(_mm256_setzero_si256(), bits.values[2], q8[2]);
+        auto p4 = _mm256_dpbusd_epi32(_mm256_setzero_si256(), bits.values[3], q8[3]);
+        sumi[0] = _mm256_dpwssd_epi32(_mm256_setzero_si256(), scales[0], _mm256_packs_epi32(p1, p2));
+        sumi[1] = _mm256_dpwssd_epi32(_mm256_setzero_si256(), scales[1], _mm256_packs_epi32(p3, p4));
 #else
         const __m256i p1 = _mm256_madd_epi16(scales[0], _mm256_maddubs_epi16(bits.values[0], q8[0]));
         const __m256i p2 = _mm256_madd_epi16(scales[1], _mm256_maddubs_epi16(bits.values[1], q8[1]));
@@ -2604,6 +2576,13 @@ inline void multiply_add_1(int j, const Bits& bits, const __m256i * scales, cons
         auto p4 = _mm256_dpbusd_epi32(_mm256_setzero_si256(), bits.values[3], q8[3]);
         sumi[0] = _mm256_dpwssd_epi32(sumi[0], scales[0], _mm256_packs_epi32(p1, p2));
         sumi[1] = _mm256_dpwssd_epi32(sumi[1], scales[1], _mm256_packs_epi32(p3, p4));
+#elif __AVXVNNI__
+        auto p1 = _mm256_dpbusd_epi32(_mm256_setzero_si256(), bits.values[0], q8[0]);
+        auto p2 = _mm256_dpbusd_epi32(_mm256_setzero_si256(), bits.values[1], q8[1]);
+        auto p3 = _mm256_dpbusd_epi32(_mm256_setzero_si256(), bits.values[2], q8[2]);
+        auto p4 = _mm256_dpbusd_epi32(_mm256_setzero_si256(), bits.values[3], q8[3]);
+        sumi[0] = _mm256_dpwssd_epi32(sumi[0], scales[0], _mm256_packs_epi32(p1, p2));
+        sumi[1] = _mm256_dpwssd_epi32(sumi[1], scales[1], _mm256_packs_epi32(p3, p4));
 #else
         const __m256i p1 = _mm256_madd_epi16(scales[0], _mm256_maddubs_epi16(bits.values[0], q8[0]));
         const __m256i p2 = _mm256_madd_epi16(scales[1], _mm256_maddubs_epi16(bits.values[1], q8[1]));
@@ -2614,11 +2593,8 @@ inline void multiply_add_1(int j, const Bits& bits, const __m256i * scales, cons
 #endif
     }
 }
-// end copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L1578
 
 
-// Copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L7278
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 inline void set_scales_8_iq(int j, const __m256i& all_scales, __m256i * scales) {
     //#ifdef HAVE_FANCY_SIMD
         auto shuffle = j == 0 ? _mm256_set_epi64x(0x0302030203020302, 0x0100010001000100, 0x0302030203020302, 0x0100010001000100)
@@ -2635,14 +2611,15 @@ inline void set_scales_16_iq(const __m256i& all_scales, __m256i * scales) {
         auto shuffle = _mm256_set_epi64x(0x0706070607060706, 0x0302030203020302, 0x0504050405040504, 0x0100010001000100);
         scales[0] = _mm256_shuffle_epi8(all_scales, shuffle);
         scales[1] = _mm256_shuffle_epi8(all_scales, _mm256_add_epi8(shuffle, _mm256_set1_epi8(8)));
+    #elif __AVXVNNI__
+        auto shuffle = _mm256_set_epi64x(0x0706070607060706, 0x0302030203020302, 0x0504050405040504, 0x0100010001000100);
+        scales[0] = _mm256_shuffle_epi8(all_scales, shuffle);
+        scales[1] = _mm256_shuffle_epi8(all_scales, _mm256_add_epi8(shuffle, _mm256_set1_epi8(8)));
     #else
         set_scales_16(all_scales, scales);
     #endif
     }
-// end copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L7278
     
-// Copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L7299
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 template <typename Dequantizer>
 static void mul_mat_qX_K_q8_K_IQ_1(int n, const void * vx, size_t bx, const DataInfo& info, int nrc_x) {
         const int nb = n / QK_K;
@@ -2738,15 +2715,13 @@ static void mul_mat_qX_K_q8_K_IQ(int n, const void * vx, size_t bx, const DataIn
     mul_mat_qX_K_q8_K_IQ_N<Dequantizer, nrc_y>(n, vx, bx, info, nrc_x);
 #endif
 }
-// end copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L7299
 
 /*
 moonll iq1s
 core func for iq1s mul_mat_iq1_s_q8_K
 
 */
-// Copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L3813
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
+
 template <int nrc_y>
 static void mul_mat_iq1_s_q8_K(int n, const void * vx, size_t bx, const DataInfo& info, int nrc_x) {
     GGML_ASSERT(n%QK_K == 0);
@@ -2800,6 +2775,11 @@ static void mul_mat_iq1_s_q8_K(int n, const void * vx, size_t bx, const DataInfo
                     auto dot1 = _mm256_dpbusd_epi32(_mm256_setzero_si256(), qx[2*ib64+0], qy1);
                     auto dot2 = _mm256_dpbusd_epi32(_mm256_setzero_si256(), qx[2*ib64+1], qy2);
                     sumi = _mm256_dpwssd_epi32(sumi, scales[ib64], _mm256_packs_epi32(dot1, dot2));
+#elif __AVXVNNI__
+                    auto dot1 = _mm256_dpbusd_epi32(_mm256_setzero_si256(), qx[2*ib64+0], qy1);
+                    auto dot2 = _mm256_dpbusd_epi32(_mm256_setzero_si256(), qx[2*ib64+1], qy2);
+                    sumi = _mm256_dpwssd_epi32(sumi, scales[ib64], _mm256_packs_epi32(dot1, dot2));
+                    //printf("======");
 #else
                     auto dot1 = _mm256_maddubs_epi16(qx[2*ib64+0], qy1);
                     auto dot2 = _mm256_maddubs_epi16(qx[2*ib64+1], qy2);
@@ -2809,6 +2789,8 @@ static void mul_mat_iq1_s_q8_K(int n, const void * vx, size_t bx, const DataInfo
                 }
 #ifdef HAVE_FANCY_SIMD
                 sumi = _mm256_dpwssd_epi32(sumi, bsums, deltas);
+#elif __AVXVNNI__
+                sumi = _mm256_dpwssd_epi32(sumi, bsums, deltas);
 #else
                 sumi = _mm256_add_epi32(sumi, _mm256_madd_epi16(bsums, deltas));
 #endif
@@ -2821,7 +2803,6 @@ static void mul_mat_iq1_s_q8_K(int n, const void * vx, size_t bx, const DataInfo
         }
     }
 }
-// end copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L3813
 
 /*
 moonll iq1s
@@ -2829,8 +2810,6 @@ DequantizerIQ2XXS
 DequantizerIQ2XXS is important Dequantizer for DequantizerIQ1_S
 */
 
-// Copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L8035
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 struct DequantizerIQ2XXS final : public BaseDequantizer<block_iq2_xxs> {
     DequantizerIQ2XXS(const void * vx, size_t bx) : BaseDequantizer(vx, bx) {}
 
@@ -2871,7 +2850,7 @@ struct DequantizerIQ2XXS final : public BaseDequantizer<block_iq2_xxs> {
 #ifdef HAVE_FANCY_SIMD
         esh.sign_2_values(MM256_SET_M128I(_mm_set1_epi32(aux32[3]), _mm_set1_epi32(aux32[1])), values+0);
         esh.sign_2_values(MM256_SET_M128I(_mm_set1_epi32(aux32[7]), _mm_set1_epi32(aux32[5])), values+2);
-#else
+#else 
         esh.sign_value(aux32[1], values[0]);
         esh.sign_value(aux32[3], values[1]);
         esh.sign_value(aux32[5], values[2]);
@@ -2911,8 +2890,6 @@ add Q8_0_Unpacker && DequantizerIQ2XXS support
 add func mul_mat_qX_K_q8_K_IQ
 */
 
-// Copied/adapted from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L9092
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 template <typename Dequantizer> void MulMat::set_functions(MulMat& m) {
     if constexpr (std::is_same_v<Dequantizer, Q4_0_Unpacker> || std::is_same_v<Dequantizer, Q5_0_Unpacker> ||
         std::is_same_v<Dequantizer, Q8_0_Unpacker>) {
@@ -2991,10 +2968,7 @@ template <typename Dequantizer> void MulMat::set_functions(MulMat& m) {
 #endif
         }
 }
-// end copied/adapted from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L9092
 
-// Copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L8622
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 struct QFBase {
     #ifdef __AVX512F__
         constexpr static int k_step = 16;
@@ -3234,7 +3208,8 @@ void set_mul_mat_f(MulMat& mm) {
     mm.funcs[5] = mul_mat_fX_fY_T<6, FloatX, FloatY>;
 #endif
 }
-// end copied from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L8622
+
+
 
 /*
 moonll
@@ -3244,8 +3219,6 @@ add IQ1_S
 add GGML_TYPE_IQ4_XS
 */
 
-// Modifications extracted from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L9231
-// MIT licensed, Copyright (c) 2024-2025 Iwan Kawrakow
 bool MulMat::set_mul_mat(int typeA, int typeB, int ne00, MulMat& mm, int Ny) {
     (void)Ny;
 
@@ -3318,16 +3291,19 @@ bool MulMat::set_mul_mat(int typeA, int typeB, int ne00, MulMat& mm, int Ny) {
             mm.funcs[5] = mul_mat_iq1_s_q8_K<6>;
             mm.funcs[6] = mul_mat_iq1_s_q8_K<7>;
             mm.funcs[7] = mul_mat_iq1_s_q8_K<8>;
-        #ifdef HAVE_FANCY_SIMD
+        #ifdef HAVE_FANCY_SIMD 
              mm.func16 = mul_mat_iq1_s_q8_K<16>;
         #endif
+        #ifdef __AVXVNNI__ 
+                mm.func16 = mul_mat_iq1_s_q8_K<16>;
+        #endif
        // row_size_q8 = ggml_row_size(GGML_TYPE_Q8_K, ne00);
               expected_typeB = GGML_TYPE_Q8_K;
             break;
 
         default:
         {
-            // printf("case:%d",typeA);
+            printf("case:%d",typeA);
             return false;
         }
             
@@ -3338,7 +3314,6 @@ bool MulMat::set_mul_mat(int typeA, int typeB, int ne00, MulMat& mm, int Ny) {
     return ggml_type(typeB) == expected_typeB;
 
 }
-// end extracted from https://github.com/ikawrakow/ik_llama.cpp/blob/474435f58b6a26bc549589966482207fee94aa60/ggml/src/iqk/iqk_mul_mat.cpp#L9231
 
 } // namespace
 
